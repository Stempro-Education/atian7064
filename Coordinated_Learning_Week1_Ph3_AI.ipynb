{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T03:02:18.781559Z",
     "start_time": "2019-12-17T03:02:18.778556Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#help(nltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK How to: \n",
    "<font size=5 color=\"read\">http://www.nltk.org/howto/</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T04:21:31.813520Z",
     "start_time": "2019-12-16T04:17:30.946240Z"
    }
   },
   "source": [
    "## Option 1 Download from choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T03:02:44.767669Z",
     "start_time": "2019-12-17T03:02:41.712547Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download()\n",
    "from IPython.display import Image\n",
    "Image(\"img/NLTK_Download.PNG\")\n",
    "# or in MarkDown: ![title](img/NLTK_Download.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T04:50:49.300915Z",
     "start_time": "2019-12-16T04:50:49.281984Z"
    }
   },
   "source": [
    "## Option 2: Explicit downloading\n",
    "<font size=6><b>Recommended only download popular or what you need</b><font><br>\n",
    "<font size=5>For example, download corpus of gutenberg </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T05:02:23.557793Z",
     "start_time": "2019-12-16T05:02:23.552826Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "<font size=5><b>use help(nltk) to browse what are there </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T05:37:58.498472Z",
     "start_time": "2019-12-16T05:37:58.492467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shakespeare-caesar.txt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = nltk.corpus.gutenberg.fileids()\n",
    "[f for f in files if \"sha\" in f][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T04:32:24.107206Z",
     "start_time": "2019-12-16T04:32:24.103202Z"
    }
   },
   "source": [
    "<html><img src=\"imgs/NLTK_Download.png\",width=60,height=60></html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T05:45:33.759034Z",
     "start_time": "2019-12-16T05:45:33.750072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a fine Workman , I am but as you would say , a Cobler Mur . But what Trade art thou ? Answer me directly Cob . A Trade Sir , that I hope I may vse , with a safe Conscience , which is indeed Sir , a Mender of bad soules Fla . What Trade thou knaue ? Thou naughty knaue , what Trade ? Cobl . Nay I beseech you Sir , be not out with me : yet if you be out Sir , I can mend you Mur . What mean ' st thou by that ? Mend mee , thou sawcy Fellow ? Cob . Why sir , Cobble you Fla . Thou art a Cobler , art thou ? Cob . Truly sir , all that I liue by , is with the Aule : I meddle with no Tradesmans matters , nor womens matters ; but withal I am indeed Sir , a Surgeon to old shooes : when they are in great danger , I recouer them . As proper men as euer trod vpon Neats Leather , haue gone vpon my handy - worke Fla . But wherefore art not in thy Shop to day ? Why do ' st thou leade these men about the streets ? Cob . Truly sir , to weare out their shooes , to get my selfe into more worke . But indeede sir , we make Holyday to see Caesar , and to reioyce in his Triumph Mur . Wherefore reioyce ? What Conquest brings he home ? What Tributaries follow him to Rome , To grace in Captiue bonds his Chariot Wheeles ? You Blockes , you stones , you worse then senslesse things : O you hard hearts , you cruell men of Rome , Knew you not Pompey many a time and oft ? Haue you climb ' d vp to Walles and Battlements , To Towres and Windowes ? Yea , to Chimney tops , Your Infants in your Armes , and there haue sate The liue - long day , with patient expectation , To see great Pompey passe the streets of Rome : And when you saw his Chariot but appeare , Haue you not made an Vniuersall shout , That Tyber trembled vnderneath her bankes To heare the replication of your sounds , Made in her Concaue Shores ? And do you now put on your best attyre ? And do you now cull out a Holyday ? And do you now strew Flowers in his way , That comes in Triumph ouer Pompeyes blood ? Be gone , Runne to your houses , fall vpon your knees , Pray to the Gods to intermit the plague That needs must light on this Ingratitude Fla . Go , go , good Countrymen , and for this fault Assemble all the poore men of your sort ; Draw them to Tyber bankes , and weepe your teares Into the Channell , till the lowest streame Do kisse the most exalted Shores of all . Exeunt . all the Commoners . See where their basest mettle be not mou ' d , They vanish tongue - tyed in their guiltinesse : Go you downe that way towards the Capitoll , This way will I : Disrobe the Images , If you do finde them deckt with Ceremonies Mur . May we do so ? You know it is the Feast of Lupercall Fla . It is no matter , let no Images Be hung with Caesars Trophees : Ile about , And driue away the Vulgar from the streets ; So do you too , where you perceiue them thicke . These growing Feathers , pluckt from Caesars wing , Will make him flye an ordinary pitch , Who else would soare aboue the view of men , And keepe vs all in seruile fearefulnesse . Exeunt . Enter Caesar , Antony for the Course , Calphurnia , Portia , Decius , Cicero , Brutus , Cassius , Caska , a Soothsayer : after them Murellus and Flauius . Caes . Calphurnia Cask . Peace ho , Caesar speakes Caes . Calphurnia Calp . Heere my Lord Caes . Stand you directly in Antonio ' s way , When he doth run his course . Antonio Ant . CÃ¦sar , my Lord Caes . Forget not in your speed Antonio , To touch Calphurnia : for our Elders say , The Barren touched in this holy chace , Shake off their sterrile curse Ant . I shall remember , When Caesar sayes , Do this ; it is perform ' d Caes . Set on , and leaue no Ceremony out Sooth . Caesar Caes . Ha ? Who calles ? Cask . Bid euery noyse be still : peace yet againe Caes . Who is it in the presse , that calles on me ? I heare a Tongue shriller then all the Musicke Cry , Caesar : Speake , Caesar is turn ' d to heare Sooth . Beware the Ides of March Caes . What man is that ? Br . A Sooth - sayer bids you beware the Ides of March Caes . Set him before me , let me see his face Cassi . Fellow , come from the throng , look vpon Caesar Caes . What sayst thou to me now ? Speak once againe , Sooth . Beware the Ides of March Caes . He is a Dreamer , let vs leaue him : Passe . Sennet Exeunt . Manet Brut . & Cass . Cassi . Will you go see the order of the course ? Brut . Not I Cassi . I pray you do Brut . I am not Gamesom : I do lacke some part Of that quicke Spirit that is in Antony : Let me not hinder Cassius your desires ; Ile leaue you Cassi . Brutus , I do obserue you now of late : I haue not from your eyes , that gentlenesse And shew of Loue , as I was wont to haue : You beare too stubborne , and too strange a hand Ouer your Friend , that loues you Bru . Cassius , Be not deceiu ' d : If I haue veyl ' d my looke , I turne the trouble of my Countenance Meerely vpon my selfe . Vexed I am Of late , with passions of some difference , Conceptions onely proper to my selfe , Which giue some soyle ( perhaps ) to my Behauiours : But let\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "#help(gutenberg)\n",
    "gwords=gutenberg.words('shakespeare-caesar.txt')\n",
    "type(gwords) #nltk.corpus.reader.util.StreamBackedCorpusView\n",
    "# it is not a list; rather it is a SteramBackedCorpusView. which is specific to nltk\n",
    "#you may conduct list style slicing:\n",
    "' '.join(gwords[123:1234])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try yourself!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:38:19.730613Z",
     "start_time": "2019-12-17T06:38:19.727585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# import the nltk te\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:38:23.652228Z",
     "start_time": "2019-12-17T06:38:23.647260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:41:48.712630Z",
     "start_time": "2019-12-17T06:41:48.709597Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.book import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:36:02.576504Z",
     "start_time": "2019-12-17T06:36:02.570490Z"
    }
   },
   "source": [
    "<b>Look at what are in the nltk.book: (nltk/book.py)</b>\n",
    " \n",
    "from nltk.corpus import (\n",
    "    gutenberg,\n",
    "    genesis,\n",
    "    inaugural,\n",
    "    nps_chat,\n",
    "    webtext,\n",
    "    treebank,\n",
    "    wordnet,\n",
    ")\n",
    "from nltk.text import Text\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import bigrams\n",
    "\n",
    "print(\"*** Introductory Examples for the NLTK Book ***\")\n",
    "print(\"Loading text1, ..., text9 and sent1, ..., sent9\")\n",
    "print(\"Type the name of the text or sentence to view it.\")\n",
    "print(\"Type: 'texts()' or 'sents()' to list the materials.\")\n",
    "\n",
    "text1 = Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "print(\"text1:\", text1.name)\n",
    "\n",
    "text2 = Text(gutenberg.words('austen-sense.txt'))\n",
    "print(\"text2:\", text2.name)\n",
    "\n",
    "text3 = Text(genesis.words('english-kjv.txt'), name=\"The Book of Genesis\")\n",
    "print(\"text3:\", text3.name)\n",
    "\n",
    "text4 = Text(inaugural.words(), name=\"Inaugural Address Corpus\")\n",
    "print(\"text4:\", text4.name)\n",
    "\n",
    "text5 = Text(nps_chat.words(), name=\"Chat Corpus\")\n",
    "print(\"text5:\", text5.name)\n",
    "\n",
    "text6 = Text(webtext.words('grail.txt'), name=\"Monty Python and the Holy Grail\")\n",
    "print(\"text6:\", text6.name)\n",
    "\n",
    "text7 = Text(treebank.words(), name=\"Wall Street Journal\")\n",
    "print(\"text7:\", text7.name)\n",
    "\n",
    "text8 = Text(webtext.words('singles.txt'), name=\"Personals Corpus\")\n",
    "print(\"text8:\", text8.name)\n",
    "\n",
    "text9 = Text(gutenberg.words('chesterton-thursday.txt'))\n",
    "print(\"text9:\", text9.name)\n",
    "\n",
    "\n",
    "def texts():\n",
    "    print(\"text1:\", text1.name)\n",
    "    print(\"text2:\", text2.name)\n",
    "    print(\"text3:\", text3.name)\n",
    "    print(\"text4:\", text4.name)\n",
    "    print(\"text5:\", text5.name)\n",
    "    print(\"text6:\", text6.name)\n",
    "    print(\"text7:\", text7.name)\n",
    "    print(\"text8:\", text8.name)\n",
    "    print(\"text9:\", text9.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5><b>Try with inaugural </b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:47:45.460453Z",
     "start_time": "2019-12-17T06:47:45.457452Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.book import inaugural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> President Trump's Inaugral is here too !</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:49:19.614351Z",
     "start_time": "2019-12-17T06:49:19.610308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:50:02.469856Z",
     "start_time": "2019-12-17T06:50:02.465829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 3 of 3 matches:\n",
      "Clinton , President Bush , President Obama , fellow Americans , and people of t\n",
      "r , and we are grateful to President Obama and First Lady Michelle Obama for th\n",
      "sident Obama and First Lady Michelle Obama for their gracious aid throughout th\n"
     ]
    }
   ],
   "source": [
    "text4.concordance(\"Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:50:35.733658Z",
     "start_time": "2019-12-17T06:50:34.263682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very_,\n"
     ]
    }
   ],
   "source": [
    "text1.common_contexts([\"bad\", \"good\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### statistics perspective of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:51:16.077292Z",
     "start_time": "2019-12-17T06:51:16.072296Z"
    }
   },
   "outputs": [],
   "source": [
    "len(text1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:54:31.186323Z",
     "start_time": "2019-12-17T06:54:31.132326Z"
    }
   },
   "outputs": [],
   "source": [
    "len(text1) / len(set(text1))   # this shows the average frequency of a word in a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:54:46.921167Z",
     "start_time": "2019-12-17T06:54:46.912205Z"
    }
   },
   "outputs": [],
   "source": [
    "text1.count(\"we\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:54:53.090456Z",
     "start_time": "2019-12-17T06:54:53.080456Z"
    }
   },
   "outputs": [],
   "source": [
    "100 * text1.count('we') / len(text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Two functions to do the statistics calculation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:55:15.391447Z",
     "start_time": "2019-12-17T06:55:15.388412Z"
    }
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text): \n",
    "    return len(text) / len(set(text)) \n",
    "\n",
    "def percentage(count, total): \n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_diversity(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:55:50.120343Z",
     "start_time": "2019-12-17T06:55:50.116315Z"
    }
   },
   "outputs": [],
   "source": [
    "percentage(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage(text4.count('a'), len(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4bdde17030fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m173\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'text4' is not defined"
     ]
    }
   ],
   "source": [
    "text4[173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:56:07.517851Z",
     "start_time": "2019-12-17T06:56:07.512854Z"
    }
   },
   "outputs": [],
   "source": [
    "text4.index('awaken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text slicing \n",
    "text4[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider each word as a string \n",
    "name = 'Monty'\n",
    "name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the frequency distribution \n",
    "fdist2 = FreqDist(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist2  # it is a dictionary with words and their frequencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary2 = fdist2.keys()  # dictionary contains (key,value), we can try to print vocabulary\n",
    "#for key, value in fdist2.items():\n",
    "#    print(key)\n",
    "sorted_x = sorted(fdist2.items(), key=lambda kv: kv[1], reverse=True)[1]\n",
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist2.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection words with criteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T06:57:16.888184Z",
     "start_time": "2019-12-17T06:57:16.837222Z"
    }
   },
   "outputs": [],
   "source": [
    "V = set(text1)\n",
    "long_words = [w for w in V if len(w) > 15]\n",
    "sorted(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'test2']\n"
     ]
    }
   ],
   "source": [
    "p = [\"test\", \"test2\"]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
